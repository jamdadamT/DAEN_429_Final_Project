{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5b6277ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b6277ca",
        "outputId": "911209d4-d6e9-4ba0-88e7-fd3c715e0ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Standard PyTorch + Torchvision stack\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "# Reproducibility (essential for research and debugging)\n",
        "import random\n",
        "SEED = 1337\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Note: For complete reproducibility, you may also need:\n",
        "# torch.backends.cudnn.deterministic = True\n",
        "# torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device (GPU if available)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1c593ca7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c593ca7",
        "outputId": "83f666b9-80b6-4d84-89cc-471cf94bdd66"
      },
      "outputs": [],
      "source": [
        "# Let's examine a fresh ResNet-18 pretrained on ImageNet\n",
        "res18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c363e3",
      "metadata": {
        "id": "88c363e3"
      },
      "source": [
        "## 3) Why Transfer Learning? The Power of Pretrained Features\n",
        "\n",
        "### The Transfer Learning Hypothesis\n",
        "\n",
        "Networks trained on large datasets (like ImageNet with 1.2M images, 1000 classes) learn hierarchical features:\n",
        "\n",
        "Early layers (conv1, layer1): Low-level features (edges, textures, colors)\n",
        "\n",
        "Middle layers (layer2, layer3): Mid-level features (shapes, parts, patterns)\n",
        "\n",
        "Deep layers (layer4): High-level, task-specific features (object parts)\n",
        "\n",
        "Final layer (fc): Class-specific decision boundaries\n",
        "\n",
        "Key Insight: Low and mid-level features are universal across vision tasks! We can reuse them and only adapt the high-level features to our new task.\n",
        "\n",
        "## Fine-Tuning Strategies\n",
        "\n",
        "### 1) Feature Extraction *(Freeze all, train head)*\n",
        "- **Pros:** Fastest; lowest overfitting risk  \n",
        "- **Use when:** Limited data; domain ≈ ImageNet  \n",
        "- **Unfrozen:** `fc` only\n",
        "\n",
        "---\n",
        "\n",
        "### 2) Shallow Fine-Tuning *(Unfreeze layer4 + head)*\n",
        "- **Pros:** Adapts high-level features; still efficient  \n",
        "- **Use when:** Moderate data; somewhat different domain  \n",
        "- **Unfrozen:** `layer4`, `fc`\n",
        "\n",
        "---\n",
        "\n",
        "### 3) Deep Fine-Tuning *(Unfreeze layer3 + layer4 + head)*\n",
        "- **Pros:** Greater adaptation capacity  \n",
        "- **Use when:** Sufficient data; noticeable domain shift  \n",
        "- **Unfrozen:** `layer3`, `layer4`, `fc`\n",
        "\n",
        "---\n",
        "\n",
        "### 4) Full Fine-Tuning *(Unfreeze everything)*\n",
        "- **Pros:** Maximum flexibility  \n",
        "- **Cons:** Slowest; higher overfitting risk  \n",
        "- **Use when:** Large dataset; very different domain  \n",
        "- **Unfrozen:** all layers\n",
        "\n",
        "---\n",
        "\n",
        "### Practical Tips\n",
        "- Prefer **smaller LR** for earlier layers (discriminative LRs).\n",
        "- Add regularization when unfreezing more (augmentations, weight decay, label smoothing).\n",
        "- Monitor validation; consider early stopping/checkpointing.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56c1c800",
      "metadata": {
        "id": "56c1c800"
      },
      "source": [
        "## 4) Data Preprocessing: Why ImageNet Statistics?\n",
        "\n",
        "### Understanding ImageNet Normalization\n",
        "Pretrained networks expect inputs with specific statistics because they were trained on normalized ImageNet data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c6c7c62b",
      "metadata": {
        "id": "c6c7c62b"
      },
      "outputs": [],
      "source": [
        "# ImageNet channel-wise statistics (computed over millions of images)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # Mean per channel (R, G, B)\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]  # Std dev per channel\n",
        "\n",
        "# Why these specific values?\n",
        "# - They center the data around 0 and scale to ~[-2, 2] range\n",
        "# - This matches the distribution the network was trained on\n",
        "# - Network weights are calibrated to these input scales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0b79974f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b79974f",
        "outputId": "ebae911a-0595-46d5-e51b-1d8cfaecdcd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Dataset: 83,996 train, 28 val\n",
            " Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'nothing', 'space'] and test classes ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'nothing', 'space']\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = 224          # Standard ImageNet size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Training transforms: Add variability to prevent overfitting\n",
        "train_tf = transforms.Compose([\n",
        "    # 1. Resize: ASL images need to be 224×224\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 3. Convert to tensor: PIL Image → Tensor, scales to [0,1]\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # 4. Normalize: Match ImageNet statistics\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "    # This does: output = (input - mean) / std\n",
        "])\n",
        "\n",
        "# Validation transforms: No augmentation (we want consistent evaluation)\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "full_train_ds = datasets.ImageFolder(root=\"C:\\\\Users\\\\jamda\\\\Downloads\\\\429.Proj\\\\asl_alphabet_train\\\\asl_alphabet_train\", transform=train_tf)\n",
        "given_test_ds   = datasets.ImageFolder(root=\"C:\\\\Users\\\\jamda\\\\Downloads\\\\429.Proj\\\\asl_alphabet_test\\\\asl_alphabet_test\",transform=val_tf)\n",
        "\n",
        "\n",
        "#Need to split full train into validation set\n",
        "indices = np.arange(len( full_train_ds ) )\n",
        "labels = np.array(full_train_ds.targets ) # ASL labels\n",
        "train_idx , val_idx = train_test_split(indices , test_size =0.2 , stratify = labels , random_state =429)\n",
        "\n",
        "\n",
        "train_subset_ds = Subset(full_train_ds, train_idx)\n",
        "\n",
        "# Create the stratified Validation Subset\n",
        "val_subset_ds = Subset(full_train_ds, val_idx)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    given_test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,         \n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "NUM_CLASSES = 28\n",
        "print(f' Dataset: {len(full_train_ds):,} train, {len(given_test_ds):,} val')\n",
        "print(f' Classes: {full_train_ds.classes} and test classes {given_test_ds.classes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e90d56c0",
      "metadata": {
        "id": "e90d56c0"
      },
      "source": [
        "## 5) Model Setup: Adapting ResNet-18 for ASL Translation\n",
        "\n",
        "Replacing the Classification Head\n",
        "\n",
        "The pretrained ResNet-18 outputs 1000 classes (ImageNet), but we need 28 (ASL no del):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b5bde5ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5bde5ef",
        "outputId": "02c0f806-e74f-4461-d561-71ce59117d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Original FC layer:\n",
            "  Input features: 512\n",
            "  Output features: 1000 (ImageNet classes)\n",
            "\n",
            " New FC layer:\n",
            "  Input features: 512\n",
            "  Output features: 28 (our classes)\n"
          ]
        }
      ],
      "source": [
        "# Start with ImageNet-pretrained weights\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Examine the original classifier\n",
        "print(\" Original FC layer:\")\n",
        "print(f\"  Input features: {model.fc.in_features}\")\n",
        "print(f\"  Output features: {model.fc.out_features} (ImageNet classes)\")\n",
        "\n",
        "# Replace with our custom classifier\n",
        "# The in_features must match (512 for ResNet-18's final feature size)\n",
        "# The NUM_CLASSES will change for other datasets\n",
        "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "\n",
        "print(\"\\n New FC layer:\")\n",
        "print(f\"  Input features: {model.fc.in_features}\")\n",
        "print(f\"  Output features: {model.fc.out_features} (our classes)\")\n",
        "\n",
        "# Move model to GPU if available\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11a03d7b",
      "metadata": {
        "id": "11a03d7b"
      },
      "source": [
        "## Understanding Parameter Names and Hierarchy\n",
        "To selectively freeze/unfreeze layers, we need to understand PyTorch's parameter naming:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e0b8ca81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0b8ca81",
        "outputId": "956673f2-1f61-47ee-bb1d-d47eadab4bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Model Structure (hierarchical view):\n",
            "├── conv1: Conv2d (9,408 params, 9,408 trainable)\n",
            "├── bn1: BatchNorm2d (128 params, 128 trainable)\n",
            "├── relu: ReLU (0 params, 0 trainable)\n",
            "├── maxpool: MaxPool2d (0 params, 0 trainable)\n",
            "├── layer1: Sequential (147,968 params, 147,968 trainable)\n",
            "│   ├── 0: BasicBlock (73,984 params, 73,984 trainable)\n",
            "│   ├── 1: BasicBlock (73,984 params, 73,984 trainable)\n",
            "├── layer2: Sequential (525,568 params, 525,568 trainable)\n",
            "│   ├── 0: BasicBlock (230,144 params, 230,144 trainable)\n",
            "│   ├── 1: BasicBlock (295,424 params, 295,424 trainable)\n",
            "├── layer3: Sequential (2,099,712 params, 2,099,712 trainable)\n",
            "│   ├── 0: BasicBlock (919,040 params, 919,040 trainable)\n",
            "│   ├── 1: BasicBlock (1,180,672 params, 1,180,672 trainable)\n",
            "├── layer4: Sequential (8,393,728 params, 8,393,728 trainable)\n",
            "│   ├── 0: BasicBlock (3,673,088 params, 3,673,088 trainable)\n",
            "│   ├── 1: BasicBlock (4,720,640 params, 4,720,640 trainable)\n",
            "├── avgpool: AdaptiveAvgPool2d (0 params, 0 trainable)\n",
            "├── fc: Linear (14,364 params, 14,364 trainable)\n"
          ]
        }
      ],
      "source": [
        "def explore_model_structure(model, max_depth=2):\n",
        "    \"\"\"Visualize the model's hierarchical structure\"\"\"\n",
        "\n",
        "    print(\"\\n Model Structure (hierarchical view):\")\n",
        "\n",
        "    def print_module(module, prefix=\"\", depth=0):\n",
        "        if depth >= max_depth:\n",
        "            return\n",
        "        for name, child in module.named_children():\n",
        "            param_count = sum(p.numel() for p in child.parameters())\n",
        "            trainable = sum(p.numel() for p in child.parameters() if p.requires_grad)\n",
        "            print(f\"{prefix}├── {name}: {child.__class__.__name__} \"\n",
        "                  f\"({param_count:,} params, {trainable:,} trainable)\")\n",
        "            if depth < max_depth - 1:\n",
        "                print_module(child, prefix + \"│   \", depth + 1)\n",
        "\n",
        "    print_module(model)\n",
        "\n",
        "# Explore structure\n",
        "explore_model_structure(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2c35761",
      "metadata": {
        "id": "d2c35761"
      },
      "source": [
        "## 6) Freezing and Unfreezing: The Core Mechanism\n",
        "### How Freezing Works\n",
        "When we \"freeze\" a layer, we set requires_grad=False on its parameters:\n",
        "\n",
        "Frozen parameters: No gradients computed, no updates during backprop\n",
        "\n",
        "Unfrozen parameters: Gradients computed, weights updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "9c5647d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c5647d8",
        "outputId": "95d3b746-760b-4951-c4ac-1d20bf9eb2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Freezing entire model...\n",
            "  ResNet: 11,190,876 parameters FROZEN\n",
            "\n",
            " Unfreezing only the FC layer...\n",
            "  Linear: 14,364 parameters UNFROZEN (trainable)\n",
            "\n",
            " Trainable: 14,364 / 11,190,876 parameters (0.128355%)\n"
          ]
        }
      ],
      "source": [
        "def set_requires_grad(module: nn.Module, requires_grad: bool):\n",
        "    \"\"\"\n",
        "    Recursively set requires_grad for all parameters in a module.\n",
        "\n",
        "    Args:\n",
        "        module: PyTorch module (layer, block, or entire model)\n",
        "        requires_grad: True to unfreeze (train), False to freeze\n",
        "    \"\"\"\n",
        "    for param in module.parameters():\n",
        "        param.requires_grad = requires_grad\n",
        "\n",
        "    # Print status\n",
        "    param_count = sum(p.numel() for p in module.parameters())\n",
        "    status = \"UNFROZEN (trainable)\" if requires_grad else \"FROZEN\"\n",
        "    print(f\"  {module.__class__.__name__}: {param_count:,} parameters {status}\")\n",
        "\n",
        "# Example: Freeze entire model, then selectively unfreeze\n",
        "print(\" Freezing entire model...\")\n",
        "set_requires_grad(model, False)\n",
        "\n",
        "print(\"\\n Unfreezing only the FC layer...\")\n",
        "set_requires_grad(model.fc, True)\n",
        "\n",
        "# Verify what's trainable\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\n Trainable: {trainable_params:,} / {total_params:,} parameters \"\n",
        "      f\"({100*trainable_params/total_params:.6f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ee588b",
      "metadata": {
        "id": "36ee588b"
      },
      "source": [
        "## 7) Training Infrastructure\n",
        "\n",
        "Training and Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "63addda7",
      "metadata": {
        "id": "63addda7"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer):\n",
        "    \"\"\"\n",
        "    Train for one epoch.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy)\n",
        "    \"\"\"\n",
        "    model.train()  # Enable dropout, batch norm training mode\n",
        "\n",
        "    total_samples = 0\n",
        "    correct_predictions = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(loader):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()  # Compute gradients\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        # Track metrics\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        correct_predictions += (predictions == labels).sum().item()\n",
        "        total_samples += images.size(0)\n",
        "\n",
        "        # Optional: Print progress\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"    Batch {batch_idx}/{len(loader)}, \"\n",
        "                  f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = running_loss / total_samples\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "@torch.no_grad()  # Decorator disables gradient computation\n",
        "def evaluate(model, loader):\n",
        "    \"\"\"\n",
        "    Evaluate model on validation/test set.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy)\n",
        "    \"\"\"\n",
        "    model.eval()  # Disable dropout, batch norm eval mode\n",
        "\n",
        "    total_samples = 0\n",
        "    correct_predictions = 0\n",
        "    running_loss = 0.0\n",
        "    all_preds = [] # <-- Collects all predicted labels\n",
        "    all_targets = []\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        # Forward pass only (no backward)\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        \n",
        "            \n",
        "        all_preds.extend(preds.cpu().tolist())\n",
        "        # FIX HERE: Use 'labels' instead of 'targets'\n",
        "        all_targets.extend(labels.cpu().tolist())\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Track metrics\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        correct_predictions += (predictions == labels).sum().item()\n",
        "        total_samples += images.size(0)\n",
        "\n",
        "\n",
        "        all_preds.extend(predictions.cpu().tolist())\n",
        "        # FIX HERE: Use 'labels' instead of 'targets'\n",
        "        all_targets.extend(labels.cpu().tolist())\n",
        "\n",
        "    avg_loss = running_loss / total_samples\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return avg_loss, accuracy, all_targets, all_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d5930662",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define dictionary that is going to hold the loss accross epochs for each model for comparison purposes\n",
        "total_loss_by_epoch_model = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "142d945e",
      "metadata": {
        "id": "142d945e"
      },
      "source": [
        "## 8) Phase 1.1: Head-Only Fine-Tuning (Feature Extraction)\n",
        "Strategy: Use ResNet as a Fixed Feature Extractor\n",
        "\n",
        "In this phase, we:\n",
        "\n",
        "1. Freeze all convolutional layers (keep ImageNet features)\n",
        "\n",
        "2. Train only the new classifier head (learn new class boundaries)\n",
        "\n",
        "3. Use higher learning rate (since we're training from scratch)\n",
        "\n",
        "This is the safest approach with limited data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "78d0ce38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "78d0ce38",
        "outputId": "152a3f61-dca6-443a-c1e4-b2d54ad36d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            " PHASE 1: HEAD-ONLY FINE-TUNING\n",
            "============================================================\n",
            "\n",
            " Freezing all layers...\n",
            "  ResNet: 11,190,876 parameters FROZEN\n",
            "\n",
            " Unfreezing classifier head...\n",
            "  Linear: 14,364 parameters UNFROZEN (trainable)\n",
            "\n",
            " Optimizer setup:\n",
            "   Learning rate: 0.001\n",
            "   Trainable params: 14,364\n",
            "\n",
            " Training progress:\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Batch 0/2100, Loss: 3.5706\n",
            "    Batch 100/2100, Loss: 2.0221\n",
            "    Batch 200/2100, Loss: 1.6068\n",
            "    Batch 300/2100, Loss: 1.1120\n",
            "    Batch 400/2100, Loss: 1.0801\n",
            "    Batch 500/2100, Loss: 0.9399\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS_HEAD_ONLY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[0;32m     70\u001b[0m val_loss, val_acc, true_labels_e, pred_labels_e \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader)\n",
            "Cell \u001b[1;32mIn[34], line 22\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, loader, optimizer)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear previous gradients\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torchvision\\models\\resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torchvision\\models\\resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\jamda\\.conda\\envs\\Pred_analytics\\lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    542\u001b[0m     )\n\u001b[1;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "#This is going to hold the losses for the different hyper paramate combinations\n",
        "head_loss_epoch_train = {}\n",
        "head_loss_epoch_val ={}\n",
        "# Hyperparameters for Phase 1\n",
        "\n",
        "EPOCHS_HEAD_ONLY = 3\n",
        "LR_HEAD = [1e-3, 1e-2, .1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" PHASE 1: HEAD-ONLY FINE-TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Step 1: Freeze entire model\n",
        "print(\"\\n Freezing all layers...\")\n",
        "set_requires_grad(model, False)\n",
        "\n",
        "# Step 2: Unfreeze only the classifier head\n",
        "print(\"\\n Unfreezing classifier head...\")\n",
        "set_requires_grad(model.fc, True)\n",
        "\n",
        "# Step 3: Create optimizer for ONLY trainable parameters\n",
        "# filter() ensures we only optimize parameters with requires_grad=True\n",
        "\n",
        "BATCH_SIZE = [32, 64, 128]\n",
        "\n",
        "for x in range(3):\n",
        "    head_loss_epoch_train[x]=[]\n",
        "    head_loss_epoch_val[x]=[]\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE[x],\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE[x],\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        "    )\n",
        "\n",
        "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    if x == 0:\n",
        "        optimizer = optim.Adam(trainable_params, lr=LR_HEAD[x])\n",
        "    elif x==1:\n",
        "        optimizer = optim.SGD(trainable_params, lr=LR_HEAD[x])\n",
        "    \n",
        "    elif x==2:\n",
        "        optim.Adagrad(trainable_params, lr=LR_HEAD[x])\n",
        "    print(f\"\\n Optimizer setup:\")\n",
        "    print(f\"   Learning rate: {LR_HEAD[x]}\")\n",
        "    print(f\"   Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    # Step 4: Training loop\n",
        "    print(\"\\n Training progress:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in range(1, EPOCHS_HEAD_ONLY + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{EPOCHS_HEAD_ONLY}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, true_labels_e, pred_labels_e = evaluate(model, val_loader)\n",
        "\n",
        "        #Append losses for plotting purposes\n",
        "        head_loss_epoch_train[x].append(train_loss)\n",
        "        head_loss_epoch_val[x].append(val_loss)\n",
        "        \n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            best_true_labels = true_labels_e\n",
        "            best_pred_labels = pred_labels_e\n",
        "            # Optional: Save best model\n",
        "            # torch.save(model.state_dict(), 'best_model_phase1.pth')\n",
        "\n",
        "        print(f\"   Train: Loss={train_loss:.4f}, Acc={train_acc:.3f}\")\n",
        "        print(f\"   Val:   Loss={val_loss:.4f}, Acc={val_acc:.3f} \"\n",
        "          f\"{' New best!' if val_acc == best_val_acc else ''}\")\n",
        "\n",
        "    print(\"\\n Phase 1 Complete!\")\n",
        "    print(f\"   Best validation accuracy: {best_val_acc:.3f}\")\n",
        "\n",
        "    #Best Epoch F1 Score\n",
        "    macro_f1 = f1_score(best_true_labels, best_pred_labels, \n",
        "                        average='macro', labels=list(range(len(full_train_ds.classes))))\n",
        "    \n",
        "    #Confustion Matrix\n",
        "    conf_matrix = confusion_matrix(best_true_labels, best_pred_labels, \n",
        "                                   labels=list(range(len(full_train_ds.classes))))\n",
        "\n",
        "    print(f\"Macro-F1 Score (Best Epoch): {macro_f1:.4f}\")\n",
        "    print(\"\\nConfusion Matrix (True vs. Predicted):\\n\")\n",
        "    print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5603562",
      "metadata": {},
      "source": [
        "# TB Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a92a97",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Redefine model for phase 2\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "\n",
        "#This is going to hold the losses for the different hyper paramate combinations\n",
        "TB_loss_epoch_train = {}\n",
        "TB_loss_epoch_val ={}\n",
        "# Hyperparameters for Phase 1\n",
        "\n",
        "EPOCHS_TB = 3\n",
        "LR_TB = [1e-3, 1e-2, .1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" PHASE 1: HEAD-ONLY FINE-TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Step 1: Freeze entire model\n",
        "print(\"\\n Freezing all layers...\")\n",
        "set_requires_grad(model, False)\n",
        "\n",
        "# Step 2: Unfreeze the classifier head and last layer\n",
        "print(\"\\n Unfreezing classifier head...\")\n",
        "set_requires_grad(model.fc, True)\n",
        "set_requires_grad(model.layer4, True)\n",
        "\n",
        "\n",
        "# Step 3: Create optimizer for ONLY trainable parameters\n",
        "# filter() ensures we only optimize parameters with requires_grad=True\n",
        "\n",
        "BATCH_SIZE = [32, 64, 128]\n",
        "\n",
        "for x in range(3):\n",
        "    TB_loss_epoch_train[x]=[]\n",
        "    TB_loss_epoch_val[x]=[]\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE[x],\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE[x],\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        "    )\n",
        "\n",
        "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    if x == 0:\n",
        "        optimizer = optim.Adam(trainable_params, lr=LR_TB[x])\n",
        "    elif x==1:\n",
        "        optimizer = optim.SGD(trainable_params, lr=LR_TB[x])\n",
        "    \n",
        "    elif x==2:\n",
        "        optim.Adagrad(trainable_params, lr=LR_TB[x])\n",
        "    print(f\"\\n Optimizer setup:\")\n",
        "    print(f\"   Learning rate: {LR_TB[x]}\")\n",
        "    print(f\"   Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    # Step 4: Training loop\n",
        "    print(\"\\n Training progress:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in range(1, EPOCHS_TB + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{EPOCHS_TB}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, true_labels_e, pred_labels_e = evaluate(model, val_loader)\n",
        "\n",
        "        #Append losses for plotting purposes\n",
        "        TB_loss_epoch_train[x].append(train_loss)\n",
        "        TB_loss_epoch_val[x].append(val_loss)\n",
        "        \n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            best_true_labels = true_labels_e\n",
        "            best_pred_labels = pred_labels_e\n",
        "            # Optional: Save best model\n",
        "            # torch.save(model.state_dict(), 'best_model_phase1.pth')\n",
        "\n",
        "        print(f\"   Train: Loss={train_loss:.4f}, Acc={train_acc:.3f}\")\n",
        "        print(f\"   Val:   Loss={val_loss:.4f}, Acc={val_acc:.3f} \"\n",
        "          f\"{' New best!' if val_acc == best_val_acc else ''}\")\n",
        "\n",
        "    print(\"\\n Phase 1 Complete!\")\n",
        "    print(f\"   Best validation accuracy: {best_val_acc:.3f}\")\n",
        "\n",
        "    #Best Epoch F1 Score\n",
        "    macro_f1 = f1_score(best_true_labels, best_pred_labels, \n",
        "                        average='macro', labels=list(range(len(full_train_ds.classes))))\n",
        "    \n",
        "    #Confustion Matrix\n",
        "    conf_matrix = confusion_matrix(best_true_labels, best_pred_labels, \n",
        "                                   labels=list(range(len(full_train_ds.classes))))\n",
        "\n",
        "    print(f\"Macro-F1 Score (Best Epoch): {macro_f1:.4f}\")\n",
        "    print(\"\\nConfusion Matrix (True vs. Predicted):\\n\")\n",
        "    print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12982a6b",
      "metadata": {},
      "source": [
        "# Model TC "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7132526",
      "metadata": {
        "id": "c7132526"
      },
      "outputs": [],
      "source": [
        "#Redefine model for phase 3\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "\n",
        "#This is going to hold the losses for the different hyper paramate combinations\n",
        "TC_loss_epoch_train = {}\n",
        "TC_loss_epoch_val ={}\n",
        "# Hyperparameters for Phase 1\n",
        "\n",
        "EPOCHS_TC = 3\n",
        "LR_TC = [1e-3, 1e-2, .1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" PHASE 1: HEAD-ONLY FINE-TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Step 1: Freeze entire model\n",
        "print(\"\\n Freezing all layers...\")\n",
        "set_requires_grad(model, False)\n",
        "\n",
        "# Step 2: Unfreeze the classifier head and last 2 layers\n",
        "print(\"\\n Unfreezing classifier head...\")\n",
        "set_requires_grad(model.fc, True)\n",
        "set_requires_grad(model.layer4, True)\n",
        "set_requires_grad(model.layer3, True)\n",
        "\n",
        "# Step 3: Create optimizer for ONLY trainable parameters\n",
        "# filter() ensures we only optimize parameters with requires_grad=True\n",
        "\n",
        "BATCH_SIZE = [32, 64, 128]\n",
        "\n",
        "for x in range(3):\n",
        "    TC_loss_epoch_train[x]=[]\n",
        "    TC_loss_epoch_val[x]=[]\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE[x],\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE[x],\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        "    )\n",
        "\n",
        "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    if x == 0:\n",
        "        optimizer = optim.Adam(trainable_params, lr=LR_TC[x])\n",
        "    elif x==1:\n",
        "        optimizer = optim.SGD(trainable_params, lr=LR_TC[x])\n",
        "    \n",
        "    elif x==2:\n",
        "        optim.Adagrad(trainable_params, lr=LR_TC[x])\n",
        "    print(f\"\\n Optimizer setup:\")\n",
        "    print(f\"   Learning rate: {LR_TC[x]}\")\n",
        "    print(f\"   Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    # Step 4: Training loop\n",
        "    print(\"\\n Training progress:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in range(1, EPOCHS_TC + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{EPOCHS_TC}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, true_labels_e, pred_labels_e = evaluate(model, val_loader)\n",
        "\n",
        "        #Append losses for plotting purposes\n",
        "        TC_loss_epoch_train[x].append(train_loss)\n",
        "        TC_loss_epoch_val[x].append(val_loss)\n",
        "        \n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            best_true_labels = true_labels_e\n",
        "            best_pred_labels = pred_labels_e\n",
        "            # Optional: Save best model\n",
        "            # torch.save(model.state_dict(), 'best_model_phase1.pth')\n",
        "\n",
        "        print(f\"   Train: Loss={train_loss:.4f}, Acc={train_acc:.3f}\")\n",
        "        print(f\"   Val:   Loss={val_loss:.4f}, Acc={val_acc:.3f} \"\n",
        "          f\"{' New best!' if val_acc == best_val_acc else ''}\")\n",
        "\n",
        "    print(\"\\n Phase 1 Complete!\")\n",
        "    print(f\"   Best validation accuracy: {best_val_acc:.3f}\")\n",
        "\n",
        "    #Best Epoch F1 Score\n",
        "    macro_f1 = f1_score(best_true_labels, best_pred_labels, \n",
        "                        average='macro', labels=list(range(len(full_train_ds.classes))))\n",
        "    \n",
        "    #Confustion Matrix\n",
        "    conf_matrix = confusion_matrix(best_true_labels, best_pred_labels, \n",
        "                                   labels=list(range(len(full_train_ds.classes))))\n",
        "\n",
        "    print(f\"Macro-F1 Score (Best Epoch): {macro_f1:.4f}\")\n",
        "    print(\"\\nConfusion Matrix (True vs. Predicted):\\n\")\n",
        "    print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea79058",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "64ac2759",
      "metadata": {},
      "source": [
        "# Full Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13024128",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Redefine model for phase 4\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "\n",
        "#This is going to hold the losses for the different hyper paramate combinations\n",
        "full_loss_epoch_train = {}\n",
        "full_loss_epoch_val ={}\n",
        "# Hyperparameters for Phase 1\n",
        "\n",
        "EPOCHS_full = 3\n",
        "LR_full = [1e-3, 1e-2, .1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" PHASE 1: HEAD-ONLY FINE-TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Step 1: Freeze entire model\n",
        "print(\"\\n Freezing all layers...\")\n",
        "set_requires_grad(model, True)\n",
        "\n",
        "# Step 2: None Frozen\n",
        "\n",
        "\n",
        "# Step 3: Create optimizer for ONLY trainable parameters\n",
        "# filter() ensures we only optimize parameters with requires_grad=True\n",
        "\n",
        "BATCH_SIZE = [32, 64, 128]\n",
        "\n",
        "for x in range(3):\n",
        "    TC_loss_epoch_train[x]=[]\n",
        "    TC_loss_epoch_val[x]=[]\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE[x],\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "    train_subset_ds,\n",
        "    batch_size=BATCH_SIZE[x],\n",
        "    shuffle=True,           \n",
        "    num_workers=2,          \n",
        "    pin_memory=True         \n",
        "    )\n",
        "\n",
        "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    if x == 0:\n",
        "        optimizer = optim.Adam(trainable_params, lr=LR_full[x])\n",
        "    elif x==1:\n",
        "        optimizer = optim.SGD(trainable_params, lr=LR_full[x])\n",
        "    \n",
        "    elif x==2:\n",
        "        optim.Adagrad(trainable_params, lr=LR_full[x])\n",
        "    print(f\"\\n Optimizer setup:\")\n",
        "    print(f\"   Learning rate: {LR_full[x]}\")\n",
        "    print(f\"   Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    # Step 4: Training loop\n",
        "    print(\"\\n Training progress:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in range(1, EPOCHS_full + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{EPOCHS_full}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, true_labels_e, pred_labels_e = evaluate(model, val_loader)\n",
        "\n",
        "        #Append losses for plotting purposes\n",
        "        full_loss_epoch_train[x].append(train_loss)\n",
        "        full_loss_epoch_val[x].append(val_loss)\n",
        "        \n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            best_true_labels = true_labels_e\n",
        "            best_pred_labels = pred_labels_e\n",
        "            # Optional: Save best model\n",
        "            # torch.save(model.state_dict(), 'best_model_phase1.pth')\n",
        "\n",
        "        print(f\"   Train: Loss={train_loss:.4f}, Acc={train_acc:.3f}\")\n",
        "        print(f\"   Val:   Loss={val_loss:.4f}, Acc={val_acc:.3f} \"\n",
        "          f\"{' New best!' if val_acc == best_val_acc else ''}\")\n",
        "\n",
        "    print(\"\\n Phase 1 Complete!\")\n",
        "    print(f\"   Best validation accuracy: {best_val_acc:.3f}\")\n",
        "\n",
        "    #Best Epoch F1 Score\n",
        "    macro_f1 = f1_score(best_true_labels, best_pred_labels, \n",
        "                        average='macro', labels=list(range(len(full_train_ds.classes))))\n",
        "    \n",
        "    #Confustion Matrix\n",
        "    conf_matrix = confusion_matrix(best_true_labels, best_pred_labels, \n",
        "                                   labels=list(range(len(full_train_ds.classes))))\n",
        "\n",
        "    print(f\"Macro-F1 Score (Best Epoch): {macro_f1:.4f}\")\n",
        "    print(\"\\nConfusion Matrix (True vs. Predicted):\\n\")\n",
        "    print(conf_matrix)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
